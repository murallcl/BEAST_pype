# Template Parameter yml for running the BDSKY-Serial-Comparative.ipynb workflow.

#Running an Instance of this Workflow
#-------------------------------------------
overall_save_dir:  # str
#    Path to where you are saving all the runs of this workflow.

#specific_run_save_dir: # str, optional (can be missing from yml)
#    Sub-directory of overall_save_dir you wish to save the outputs from this workflow.
#    If null (None in python), 'null (None in python)' or an empty string a timestamp of format 'YYYY-MM-DD_hour-min-sec' is used instead.

max_threads:  #int, default (can be missing from yml) null (None in python)
#    The maximum number of threads to use when calling gnu parallel in phases 2i and 4. If null (None in python) and BEAST_pype is running
#    in a SLURM job the SLURM environment variable `SLURM_CPUS_PER_TASK` is used. If null (None in python) and BEAST_pype is NOT running in
#    a SLURM job the number of cores available minus 1 is used (`multiprocessing.cpu_count() - 1`).


#General Inputs
#----------------
template_xml_path: # str
#    Path to template BEAST 2 xml.

fasta_path: #str
#    Path to fasta file containing sequences to be placed into template xml.

metadata_path: #str
#    Path to csv or tsv containing metadata for sequences in fasta_path.

sample_id_field: #str
#    Name of field in metadata_db containing sequence IDs.

collection_date_field: #str
#    Name of field in metadata_db containing collection dates of sequences. Should be formatted YYYY-MM-DD.

#Defining XML Sets (Partitioning Data)
#--------------------------------------------
xml_set_definitions:  #dict {str: str}
    #    The definitions for the xml_sets you wish to use.
    #    Keys:   The name used for the xml_set. Will be used to name directories so certain characters should be
     #              avoided see https://www.mtu.edu/umc/services/websites/writing/characters-avoid/.
    #    Values: Will be used with pandas DataFrame.query to seperate out your data see:
     #                   * https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html
      #                  * https://sparkbyexamples.com/pandas/pandas-dataframe-query-examples/
      #                  * https://www.slingacademy.com/article/pandas-working-with-the-dataframe-query-method-5-examples/

data_filter: #str
#    Optional can be an empy string or 'null (None in python)'. Additional filter applieid to metadata_db when selecting
#    sequences and metadata to be used on pipeline. Must conform to [pandas documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html), see further [example](https://www.slingacademy.com/article/pandas-working-with-the-dataframe-query-method-5-examples/).

#Initial Tree Building & Downsampling
#------------------
use_initial_tree:  #bool, default (can be missing from yml) True
#    If False an initial tree will not be generated skipping Phases 2i and 2ii. As such, in phase 4 BEAST 2 generate its own
#    initial tree.

initial_tree_type: #str (either 'Distance' or 'Temporal') or null (None in python), default (can be missing from yml) 'Temporal'
#    Intial tree type to use.
#    If 'Distance' the IQtree tree from Phase-2i-IQTree-Building.ipynb is used for the
#    initial tree and phase 2ii is skipped.
#    if 'Temporal' the TreeTime tree from Phase-2ii-TreeTime-and-Down-Sampling.ipynb
#    is used for the initial tree.

down_sample_to: #int
#    If the number sequences in a fasta file is above this the number of sequences is cut to this number via downsampling.

#BDSky Options
#------------------
origin_start_addition: #float, optional (can be missing from yml)
#    Suggested infection period of pathogen. **Should be in years.** This + initial MLE tree height is used as starting value of origin.

origin_upper_addition: #float/int, optional (can be missing from yml)
#    This + initial MLE tree height is used as upper value of origin prior.

origin_prior: #dict {'lower': float, 'upper': float, 'start': float}, optional (can be missing from yml)
#    Details of the origin prior assumed to be uniformly distributed.

rt_dims: #int, optional (can be missing from yml)
#    Number of Rt dimensions (time periods over which Rt is estimated).

rt_changes:  # dict of strings {'unit': 'days, weeks, months or years', 'every': int/float, 'end': date str YYYY-MM-DD}, optional (can be missing from yml)
#    Instructions for setting rt_change date, going backwards from the youngest date provided in that xml_set's metadata until rt_changes["end"]  is reached.
#    If rt_changes["end"] is not given the oldest date provided in that xml_set's metadata is used for this end point value instead.
#    rt_changes["end"] should be a datetime object or string of format YYYY-MM-DD'.
#    If given rt_dims must equal null (None in python).


sampling_prop_dims: #int, optional (can be missing from yml)
#    Number of Rt dimensions (time periods over which Rt is estimated).

sampling_prop_changes:  # dict of strings {'unit': 'days, weeks, months or years', 'every': int/float, 'end': date str YYYY-MM-DD}, optional (can be missing from yml)
#    Instructions for setting sampling_prop_change date, going backwards the youngest date provided in that xml_set's metadata until sampling_prop_changes["end"]  is reached.
#    If sampling_prop_changes["end"] is not given the oldest date provided in that xml_set's metadata is used for this end point value instead.
#    sampling_prop_changes["end"] should be a datetime object or string of format YYYY-MM-DD'.
#    If given sampling_prop_dims must equal null (None in python).

zero_sampling_before_first_sample: #bool, default (can be missing from yml) False
#    If true fix the sampling proportion to 0 for the period before the first xml_set.

#MCMC Tree/Logfile names Chain-lengths & Save Steps
#------------------
log_file_basename: # str, (required if not using a `ready_to_go_xml`)
#    If provided .tree, .log and .state files from running BEAST 2 will have this name prefixed by 'run-with-seed-{seed}-',
#    number being that of the chain.

#chain_length:  # int, optional (can be missing from yml)
#    Suggested value 10000000
#    Number of chains to use for BEAST runs.
#    If not given value in template_xml_path will be used.

#trace_log_every: # int > 1 or float between 0 and 1 optional (can be missing from yml)
#    Suggested value 0.001.
#    How often to save a log file during BEAST runs.
#    If float the save will happen as multiple of the chain_length rounded to the nearest integer.
#    If not given value in template_xml_path will be used.

#tree_log_every: # int > 1 or float between 0 and 1 optional (can be missing from yml)
#    Suggested value 0.001.
#    How often to save a log file during BEAST runs.
#    If float the save will happen as multiple of the chain_length rounded to the nearest integer.
#    If not given value in template_xml_path will be used.

#screen_log_every: # int > 1 or float between 0 and 1 optional (can be missing from yml)
#    Suggested value 0.005.
#    How often to save a log file during BEAST runs.
#    If float the save will happen as multiple of the chain_length rounded to the nearest integer.
#    If not given value in template_xml_path will be used.

#store_state_every: # int > 1 or float between 0 and 1 optional (can be missing from yml)
#    Suggested value 0.001.
#    How often to save a log file during BEAST runs.
#    If float the save will happen as multiple of the chain_length rounded to the nearest integer.
#    If not given value in template_xml_path will be used.


# Running BEAST 2
# --------------------
number_of_beast_runs: # int
#    Number of chains to use (number of parallel runs to do) when running BEAST (e.g. 9).

#seeds: # list of ints, (optional, can be missing from yml)
#    Seeds to use when running BEAST.
#    If given, length of list should be the same as the number of chains (so each run has a designated seed).

# Using a GPU when running BEAST 2
# ---------------------------------------------------------------------------------------------------
# Would you like to use a GPU when running BEAST 2?
# If so then:
# * Keep  `beast_options_without_a_value:` and   `'-beagle_GPU'` as is.
# Otherwise:
# * Comment out `beast_options_without_a_value:` and   `'-beagle_GPU'`

beast_options_without_a_value: # list of strs
  - '-beagle_GPU'
#    Options not needing a value to pass to BEAST 2.
#    For instance to use a GPU when running BEAST 2 this would be `['-beagle_GPU']`.
#    See https://www.beast2.org/2021/03/31/command-line-options.html.

# Use multiple cores/threads when running BEAST 2.
#-------------------------------------------------------------------------
# Would you like to use multiple cores/threads when running BEAST 2?
# If so then:
# * Alter the 3 after `'-threads'` to the number of cores/threads to use when
#    running BEAST 2?
# Otherwise:
# * Comment out `beast_options_needing_a_value:` and   `'-threads'`

beast_options_needing_a_value: # dict
  '-threads':
#    Option needing a value to pass to BEAST 2.
#    For instance to use 3 threads when running BEAST 2 this would be: {'-threads': 3}.
#    See https://www.beast2.org/2021/03/31/command-line-options.html.

# Using a SLURM when running BEAST 2
# ---------------------------------------------------------------------------------------------------
# Would you like each BEAST 2 run (MCMC chain) to run in a SLURM `sbatch` call.
# If so then:
# * Keep  `sbatch_options_needing_a_value:`.
# * Alter the entries under `sbatch_options_needing_a_value:` to your requirements.
#     * If not using a GPU comment out `'--gpus':.
#     * It is suggested that `--cpus-per-task` match the '-threads' entry in beast_options_needing_a_value.
#     * Max runtime`(--time`) should be increased to more than an hour.
# * If there are options you wish to pass to sbatch not requiring a value:
#    - Uncomment `sbatch_options_without_a_value`.
#    - Add those options under `sbatch_options_without_a_value` as a list (see https://yamline.com/tutorial/).
# Otherwise:
# * Comment out everything below.
sbatch_options_needing_a_value:
#  Options requiring a value to pass to sbatch.
#  See https://slurm.schedmd.com/sbatch.html.
  '--cpus-per-task':   # Number of CPU cores to use (suggest matching '-threads' entry in beast_options_needing_a_value).
#  '--gpus':  # Number of GPU cores to use
  '--time': # Maximum runtime (D-HH:MM:SS)
  '--mem':  # RAM to use.
  '--partition': # Many slurm clusters require you to name a partition to use.

#sbatch_options_without_a_value:
